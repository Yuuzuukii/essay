内容梗概
大規模言語モデル（LLM）を用いた質問応答システムは,さまざまなアプリケーション,システムなど多様な領域で実用化が進んでいる.多文化共生社会においては,質問応答は単なる情報検索にとどまらず,異なる文化的・宗教的・倫理的背景をもつ人々の相互理解を促進する役割が求められている.近年,LLMに複数の価値観や立場を付与したマルチエージェント対話が提案され,模擬的な議論や意思決定を生成する技術が登場している.
しかしながら, 既存のLLMベースのマルチエージェント対話は,対立する立場をもとに勝敗を決めるディベート的議論が多く,最終的な結論も表層的な折衷案の提示である.たとえば、「学校清掃を生徒が行うべきか職員が行うべきか」といったトピックにおいて,現状のLLMは「日常清掃は生徒,専門清掃は職員」といった妥協案を返す傾向があるが,これは価値の統合ではなく単なる分業の提案にすぎない.価値観の本質的な対立を踏まえ, 清掃を教育活動として再定義した生徒と職員の共同清掃のような止揚的解決の回答生成は依然として実現できていない.
そこで，本研究では，多様な価値観の対立を扱うトピックを対象に，LLMを用いたマルチエージェント対話によって新たな価値・制度・概念の再構成（止揚）を導く弁証法的な対話プロトコルを提案する.具体的には，Sawamura, Umedaら[1]の記号論理に基づく既存の弁証法議論の手続きを参照し，その形式的プロセスをLLMマルチエージェントが自然言語で模倣できるように再構成した段階的対話モデルを設計する.
本手法の実現にあたり，取り組むべき課題は以下の1点である．
・記号論理と自然言語の違いに起因する統合プロセスと一貫性保持の困難性
弁証法的議論では，各エージェントが立場を一貫して保持しつつ議論を行い，その対立構造を維持した上で，高次の概念として統合（止揚）を生成することが求められる.しかしLLMエージェントは明示的な知識ベースや立場をもたず，対話中に主張が揺らぎやすいため，弁証法議論に必要な立場の一貫性が損なわれやすい.また，統合（止揚）は折衷ではなく価値の再構成による高次な概念の創出を意味するが，その成立条件は自然言語では明確化されておらず，形式的定義だけでは意味的統合として妥当かを判断できない.
本研究では，弁証法議論に必要な「立場の一貫性」を確保するため，まず論証構築フェーズにおいて各エージェントに主張とその前提を明示的に提示させ，次に反対論証構築フェーズにおいて対立する主張とその前提を提出させるプロセスを設計した.これにより，エージェントの立場と前提が議論開始時点で外部的に固定され，その後の反論・再構成の過程がそれらに基づいて展開されるよう制御した.また，反論段階では，記号論理における攻撃関係の構造を参考に，反論の成立条件を自然言語レベルで再定義し，各発話が初期の立場および提示された前提と矛盾しないよう議論の一貫性を確保した.
統合（止揚）は反論フェーズにて議論を行ったあと、完全に打破されていない、もしくは正当化されていない論証を対象として行うようにした。その際，折衷案とは異なる弁証法的統合を得るために，対立する二つの論証に共通する価値を抽出し，それらをより抽象度の高い上位概念へとまとめ上げる木藤, 栗原ら[2]の一般化（Generalization）の手法を導入した。一般化により，双方の主張を単に接続するのではなく，両者を包摂する新たな概念枠組みを形成しやすくなる。これらの検討結果を踏まえて統合生成用プロンプトを構築し，生成された統合案については定性的評価により，意味的な妥当性や対立包摂の程度を確認した。
本研究の貢献は以下の通りである．
貢献1：LLMエージェントを用いて, 弁証法議論を実装したこと 
これまで記号論理を用いた弁証法議論の形式的定義に関する研究は行われてきたが, 実際に対話トピックを用いて自然言語で対話をさせるものは少なかった.本研究では, 弁証法議論の形式的定義に準拠しつつ, LLMエージェントを用いて自然言語で対話を行わせる最初の試みになった.
貢献2：提案プロトコルを用いた弁証法的統合生成の実証
実装したLLMマルチエージェント対話システムにより，複数の対立テーマで統合生成を実行し，従来の単なる折衷案では得られない弁証法的統合が生成されることを確認した．
 
